{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85810021",
   "metadata": {},
   "source": [
    "## Converts TextGrids to CSV\n",
    "\n",
    "This Jupyter Notebook converts TextGrids to CSV files to be easier analyzed. This script is written with the .flac and .TextGrid files from the Seoul Corpus (Yun et al. 2015) in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3da16eb",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3d6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from praatio import textgrid\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd15494",
   "metadata": {},
   "source": [
    "## tg2df\n",
    "\n",
    "*Modified from \"Doing phonetic research on the Seoul Corpus\" paper and scripts. Located at https://osf.io/ukh6d/overview?view_only=d9bda726aebe4512830c6996f2ae4cae*\n",
    "\n",
    "**tb2df** creates a dataframe with all the information in the specified tier.\n",
    "\n",
    "For the Seoul Corpus data, the tiers are the following:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 -- Phoneme  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1 -- Word/Eojeol (pronounced, hangeul)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2 -- Word/Eojeol (pronounced, IPA)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3 -- Utterance (prononced)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4 -- Word/Eojeol (orthography, hangeul)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5 -- Word/Eojeol (orthography, IPA)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6 -- Utterance (orthography)\n",
    "\n",
    "**Inputs**:\n",
    "- string&nbsp;&nbsp;&nbsp;*filename*\n",
    "- int&nbsp;&nbsp;&nbsp;*tier_num*\n",
    "\n",
    "**Outputs**: (dataframe) of TextGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa8e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tg2df(filename, tier_num):\n",
    "  tg = textgrid.openTextgrid(filename, includeEmptyIntervals=True, duplicateNamesMode='rename')\n",
    "  tiers = tg.tierNames\n",
    "  \n",
    "  tier = tg.getTier(tiers[tier_num])\n",
    "  InputFile = filename[:-9]  \n",
    "  data = [(InputFile, label, start, end) for start, end, label in tier.entries]\n",
    "  df = pd.DataFrame(data, columns=['InputFile', 'text', 'start', 'end'])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a391a",
   "metadata": {},
   "source": [
    "## merge_all_tgs\n",
    "\n",
    "*Modified from \"Doing phonetic research on the Seoul Corpus\" paper and scripts. Located at https://osf.io/ukh6d/overview?view_only=d9bda726aebe4512830c6996f2ae4cae*\n",
    "\n",
    "**merge_all_tgs** takes a list of files and performs tg2df to all the files, combining them into one dataframe. \n",
    "\n",
    "**Inputs**:\n",
    "- string list&nbsp;&nbsp;&nbsp;*list_of_files*\n",
    "- int&nbsp;&nbsp;&nbsp;*tier_num*\n",
    "\n",
    "**Outputs**: (dataframe) of the textgrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837b4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_tgs(list_of_files, tier_num):\n",
    "  df = pd.DataFrame()\n",
    "  for f in tqdm(list_of_files, leave=True):\n",
    "    cur_data = tg2df(f, tier_num)\n",
    "    df = pd.concat([df, cur_data], axis = 0, ignore_index=True)\n",
    "  df = df.sort_values(by=['InputFile', 'start']).reset_index(drop=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d16a1",
   "metadata": {},
   "source": [
    "## get_filelist\n",
    "\n",
    "**get_filelist** gets a list of the files that we want to analyze.\n",
    "\n",
    "**Inputs**:\n",
    "- Path()&nbsp;&nbsp;&nbsp;*path*\n",
    "- string&nbsp;&nbsp;&nbsp;*extension*\n",
    "\n",
    "**Outputs**: (string list) of filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82141797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filelist(path, extention):\n",
    "    return [f.name for f in path.glob(\"*.\" + extention)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd98697d",
   "metadata": {},
   "source": [
    "## get_subsection\n",
    "\n",
    "**get_subsection** takes the list of files from the Seoul Corpus and filters it according to age (inclusive) and gender (\"m\" or \"f\").\n",
    "\n",
    "Seoul Corpus filenames are written like:  **s01m16f1**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s01 -- Speaker 1  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m16 -- 16 year old male  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;f -- Interviewer gender  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1 -- File number  \n",
    "\n",
    "**Inputs**:\n",
    "- string list&nbsp;&nbsp;&nbsp;*filenames*\n",
    "- int&nbsp;&nbsp;&nbsp;*age*\n",
    "- string&nbsp;&nbsp;&nbsp;*gender* (\"m\" or \"f\")\n",
    "\n",
    "**Outputs**: (string list) of filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d5a7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsection(filenames, age=None, gender=None):\n",
    "    new_filenames = []\n",
    "    count = 0\n",
    "\n",
    "    for filename in filenames:\n",
    "        g = filename[3]\n",
    "        a = int(filename[4:6])\n",
    "\n",
    "        if gender is not None and g != gender:\n",
    "            continue\n",
    "\n",
    "        if age is not None and not (age[0] <= a <= age[1]):\n",
    "            continue\n",
    "\n",
    "        count += 1\n",
    "        new_filenames.append(filename)       \n",
    "\n",
    "    return new_filenames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
